{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4484b7-cdde-4a41-845e-4191a74d21c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mA execução de células com 'face_project (Python 3.11.5)' requer o pacote ipykernel.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Crie um ambiente Python</a> com os pacotes necessários."
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow torch numpy matplotlib torchvision scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ TensorFlow encontrou {len(gpus)} GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "    \n",
    "    # Verifica se uma operação simples é alocada na GPU\n",
    "    try:\n",
    "        print(\"\\nAttempting a test operation on the GPU...\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "            b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "        print(\"✅ Teste de operação na GPU foi bem-sucedido.\")\n",
    "        print(\"✅ Isso confirma que o TensorFlow pode usar a GPU para os cálculos.\")\n",
    "        print(\"Se o treino ainda estiver lento, o problema pode ser um gargalo de dados (pouco provável com MNIST) ou outra configuração.\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(\"\\n❌ Ocorreu um erro durante o teste de operação na GPU:\")\n",
    "        print(e)\n",
    "        print(\"\\n❌ Isso sugere um problema de compatibilidade com CUDA/CuDNN dentro do ambiente conda.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ ERRO CRÍTICO: TensorFlow não encontrou nenhuma GPU.\")\n",
    "    print(\"❌ O treinamento será executado na CPU, o que explica a lentidão extrema.\")\n",
    "    print(\"Por favor, verifique a instalação dos drivers da NVIDIA e do ambiente conda.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bac694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- CORREÇÃO DE CAMINHO ---\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "# --- OTIMIZAÇÃO DE MEMÓRIA DA GPU ---\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#  try:\n",
    "#    for gpu in gpus:\n",
    "#      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#    print(f\"Otimização de memória (Memory Growth) ativada para {len(gpus)} GPU(s).\")\n",
    "#  except RuntimeError as e:\n",
    "#    print(e)\n",
    "\n",
    "# --- IMPORTS DO PROJETO ---\n",
    "from config.training_config import CosFaceConfig\n",
    "from src.backbones import vgg8\n",
    "from src.optimizers.scheduler import CosineAnnealingScheduler\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, TerminateOnNaN\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "print(\"Setup completo. Módulos e configurações carregados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2: Definição dos Parâmetros do Experimento\n",
    "class Args:\n",
    "    arch = 'vgg8_cosface'\n",
    "    num_features = 3\n",
    "    scheduler = 'CosineAnnealing'\n",
    "    epochs = 50\n",
    "    batch_size = 64\n",
    "    optimizer = 'SGD'\n",
    "    lr = 0.5\n",
    "    min_lr = 0.005\n",
    "    momentum = 0.5\n",
    "    name = f'mnist_{arch}_{num_features}d'\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2810d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 3: Preparação de Pastas e Dados\n",
    "checkpoint_dir = f'../experiments/checkpoints/{args.name}'\n",
    "log_path = f'../experiments/logs/{args.name}_log.csv'\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs('../experiments/logs/', exist_ok=True)\n",
    "\n",
    "print('Config -----')\n",
    "for arg in vars(args):\n",
    "    print(f'{arg}: {getattr(args, arg)}')\n",
    "print('------------')\n",
    "\n",
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "X = X[:, :, :, tf.newaxis].astype('float32') / 255\n",
    "X_test = X_test[:, :, :, tf.newaxis].astype('float32') / 255\n",
    "y = tf.keras.utils.to_categorical(y, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42446f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path):\n",
    "    \"\"\"Plota e salva as curvas de acurácia e perda.\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Encontra dinamicamente as chaves corretas\n",
    "    acc_key = next((k for k in history.history.keys() if 'accuracy' in k and 'val' not in k), 'accuracy')\n",
    "    val_acc_key = next((k for k in history.history.keys() if 'accuracy' in k and 'val' in key), 'val_accuracy')\n",
    "    \n",
    "    # Plot de Acurácia\n",
    "    ax1.plot(history.history[acc_key], label='Treino Acurácia')\n",
    "    ax1.plot(history.history[val_acc_key], label='Validação Acurácia')\n",
    "    ax1.set_title('Histórico de Acurácia')\n",
    "    ax1.set_xlabel('Época')\n",
    "    ax1.set_ylabel('Acurácia')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot de Perda\n",
    "    ax2.plot(history.history['loss'], label='Treino Perda')\n",
    "    ax2.plot(history.history['val_loss'], label='Validação Perda')\n",
    "    ax2.set_title('Histórico de Perda')\n",
    "    ax2.set_xlabel('Época')\n",
    "    ax2.set_ylabel('Perda')\n",
    "    ax2.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'training_history.png'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, X_test, y_test_cat, save_path):\n",
    "    \"\"\"Plota e salva a matriz de confusão.\"\"\"\n",
    "    y_pred_probs = model.predict([X_test, y_test_cat])\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test_cat, axis=1)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.xlabel('Predito')\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.savefig(os.path.join(save_path, 'confusion_matrix.png'))\n",
    "    plt.show()\n",
    "\n",
    "def plot_learning_rate(history, save_path):\n",
    "    \"\"\"Plota e salva o histórico da taxa de aprendizado.\"\"\"\n",
    "    if 'lr' in history.history:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(history.history['lr'], label='Taxa de Aprendizagem')\n",
    "        plt.title('Agendamento da Taxa de Aprendizagem')\n",
    "        plt.xlabel('Época')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_path, 'learning_rate_schedule.png'))\n",
    "        plt.show()\n",
    "\n",
    "print(\"Funções de plotagem prontas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a configuração\n",
    "config = CosFaceConfig()\n",
    "FIGURES_PATH = 'reports/figures'\n",
    "\n",
    "# Prepara pastas\n",
    "os.makedirs(os.path.dirname(config.CHECKPOINT_PATH), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(config.LOG_PATH), exist_ok=True)\n",
    "os.makedirs(FIGURES_PATH, exist_ok=True)\n",
    "\n",
    "# Carrega Dados\n",
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "X = X[..., tf.newaxis].astype('float32') / 255\n",
    "X_test = X_test[..., tf.newaxis].astype('float32') / 255\n",
    "y_cat = tf.keras.utils.to_categorical(y, 10)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Compila Modelo\n",
    "optimizer = SGD(learning_rate=config.LEARNING_RATE, momentum=config.MOMENTUM)\n",
    "model = getattr(vgg8, config.ARCH)(config)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Callbacks\n",
    "model_checkpoint = ModelCheckpoint(config.CHECKPOINT_PATH, verbose=1, save_best_only=True)\n",
    "weights_checkpoint_path = config.CHECKPOINT_PATH.replace('.keras', '.weights.h5')\n",
    "weights_checkpoint = ModelCheckpoint(weights_checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "callbacks = [model_checkpoint, weights_checkpoint, CSVLogger(config.LOG_PATH), TerminateOnNaN()]\n",
    "if config.SCHEDULER == 'CosineAnnealing':\n",
    "    callbacks.append(CosineAnnealingScheduler(T_max=config.EPOCHS, eta_max=config.LEARNING_RATE, eta_min=config.MIN_LEARNING_RATE, verbose=1))\n",
    "\n",
    "# Treinamento\n",
    "history = model.fit([X, y_cat], y_cat, validation_data=([X_test, y_test_cat], y_test_cat),\n",
    "                    batch_size=config.BATCH_SIZE,\n",
    "                    epochs=config.EPOCHS,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)\n",
    "\n",
    "print(\"\\n--- Treinamento Concluído ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Iniciando Análise Pós-Treino ---\")\n",
    "# Carrega o melhor modelo salvo para a análise\n",
    "model.load_weights(weights_checkpoint_path)\n",
    "\n",
    "# Gera os gráficos\n",
    "plot_training_history(history, FIGURES_PATH)\n",
    "plot_confusion_matrix(model, X_test, y_test_cat, FIGURES_PATH)\n",
    "plot_learning_rate(history, FIGURES_PATH)\n",
    "\n",
    "print(\"Análise concluída. Gráficos salvos em 'reports/figures/'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
